{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["# @title\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"LATIyd-i7tLY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pwd"],"metadata":{"id":"qoXFSTc47uMx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["try:\n","    import geopandas as gpd\n","except ModuleNotFoundError:\n","    if 'google.colab' in str(get_ipython()):\n","        !pip install geopandas --quiet\n","    else:\n","        print('geopandas not found, please install via conda in your environment')"],"metadata":{"id":"j6CLfIdR7z2-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import joblib\n","import numpy as np\n","import pandas as pd\n","from sklearn.preprocessing import StandardScaler, Normalizer, OneHotEncoder\n","from sklearn.impute import SimpleImputer\n","from sklearn.cluster import MiniBatchKMeans\n","from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score\n","from sklearn.decomposition import PCA\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from tqdm import tqdm"],"metadata":{"id":"cXLumpdRni_B"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["MODEL_VERSION = \"v2\"\n","INFERENCE_METRICS = \"inference\"\n","\n","# File Paths\n","DATASET_CSV = \"/content/drive/MyDrive/IPAUA_Maz/dataset/synthetic_data_zones_4_and_9.csv\"\n","MODEL_FILE = f\"/content/drive/MyDrive/IPAUA_Maz/models/kmeans_model_{MODEL_VERSION}.pkl\"\n","METRICS = f\"/content/drive/MyDrive/IPAUA_Maz/models/kmeans_{INFERENCE_METRICS}_metrics.csv\"\n","DATA_WITH_CLUSTERS = \"/content/drive/MyDrive/IPAUA_Maz/dataset/data_with_clusters.csv\"\n","ENCODERS_FILE = '/content/drive/MyDrive/IPAUA_Maz/models/encoders.pkl'"],"metadata":{"id":"VuNHRcmNjjlr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def preprocess_data(data, features, use_normalizer=False):\n","    # Separate numeric and categorical features\n","    numeric_features = data[features].select_dtypes(include=[np.number]).columns.tolist()\n","    categorical_features = data[features].select_dtypes(include=['object', 'category']).columns.tolist()\n","\n","    # Impute missing values for numeric features\n","    tqdm.pandas(desc=\"Imputing missing values for numeric features\")\n","    imputer_numeric = SimpleImputer(strategy=\"mean\")\n","    X_numeric_imputed = imputer_numeric.fit_transform(data[numeric_features].progress_apply(lambda x: x))\n","\n","    # Scale numeric features\n","    tqdm.pandas(desc=\"Scaling numeric features\")\n","    scaler = StandardScaler()\n","    X_numeric_scaled = scaler.fit_transform(X_numeric_imputed)\n","\n","    if use_normalizer:\n","        tqdm.pandas(desc=\"Normalizing numeric features\")\n","        normalizer = Normalizer()\n","        X_numeric_normalized = normalizer.fit_transform(X_numeric_scaled)\n","        X_numeric = X_numeric_normalized\n","    else:\n","        X_numeric = X_numeric_scaled\n","\n","    # Impute missing values for categorical features\n","    tqdm.pandas(desc=\"Imputing missing values for categorical features\")\n","    imputer_categorical = SimpleImputer(strategy=\"most_frequent\")\n","    X_categorical_imputed = imputer_categorical.fit_transform(data[categorical_features].progress_apply(lambda x: x))\n","\n","    # Encode categorical features\n","    tqdm.pandas(desc=\"Encoding categorical features\")\n","    encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n","    X_categorical_encoded = encoder.fit_transform(X_categorical_imputed)\n","\n","    # Combine numeric and categorical features\n","    X_combined = np.hstack((X_numeric, X_categorical_encoded))\n","\n","    # return X_combined, data\n","    return X_combined\n","\n","\n","# Load the trained K-means model\n","def load_model(file_name):\n","    return joblib.load(file_name)\n","\n","\n","# Load and preprocess new data\n","def load_and_preprocess_data(file_path, features, use_normalizer=False):\n","    # Load the new data\n","    data = pd.read_csv(file_path)\n","\n","    # Drop unnecessary columns which are not in features list\n","    columns_to_drop = [col for col in data.columns if col not in features]\n","    data = data.drop(columns=columns_to_drop)\n","\n","    # Preprocess the new data\n","    X_scaled = preprocess_data(data, features)\n","\n","    return X_scaled, data\n","\n","\n","# Calculate performance metrics\n","def calculate_performance_metrics(X_scaled, clusters, kmeans):\n","    metrics = {}\n","    # metrics['Inertia'] = kmeans.inertia_\n","    # metrics['Silhouette Score'] = silhouette_score(X_scaled, clusters)\n","    metrics['CHI Score'] = calinski_harabasz_score(X_scaled, clusters)\n","    metrics['DBI Score'] = davies_bouldin_score(X_scaled, clusters)\n","    return metrics\n","\n","\n","# Perform inference and calculate metrics\n","def perform_inference(model_file, data_file, features):\n","    # Load the trained model\n","    kmeans = load_model(model_file)\n","\n","    # Load and preprocess the new data\n","    X_scaled, data = load_and_preprocess_data(data_file, features)\n","\n","    # Predict the clusters for the new data\n","    clusters = kmeans.predict(X_scaled)\n","\n","    # Calculate performance metrics\n","    metrics = calculate_performance_metrics(X_scaled, clusters, kmeans)\n","    for metric, value in tqdm(metrics.items(), desc=\"Calculating performance metrics\"):\n","        print(f\"{metric}: {value}\")\n","\n","    return X_scaled, data, clusters, metrics\n","\n","\n","# Function to visualize clusters\n","def visualize_clusters(X_scaled, clusters, title):\n","    pca = PCA(n_components=2)\n","    X_pca = pca.fit_transform(X_scaled)\n","    plt.figure(figsize=(10, 8))\n","    sns.scatterplot(x=X_pca[:, 0], y=X_pca[:, 1], hue=clusters, palette=\"viridis\")\n","    plt.title(title)\n","    plt.xlabel(\"PCA Component 1\")\n","    plt.ylabel(\"PCA Component 2\")\n","    plt.legend(title=\"Cluster\")\n","    plt.show()\n","\n","\n","# Function to visualize areas on map\n","def visualize_areas_on_map(best_areas, title):\n","    plt.figure(figsize=(10, 10))\n","    scatter = plt.scatter(\n","        best_areas[\"Longitude\"], best_areas[\"Latitude\"],\n","        c=best_areas[\"Cluster\"], cmap=\"viridis\", s=50\n","    )\n","    plt.title(title)\n","    plt.xlabel(\"Longitude\")\n","    plt.ylabel(\"Latitude\")\n","    plt.colorbar(scatter, label=\"Cluster\")\n","    plt.show()"],"metadata":{"id":"XXFcDUH2hs1v"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Define features for preprocessing\n","features = [\n","    \"soil_moisture\",\n","    \"NDBI\",\n","    # \"BU\", # Dropped since BU is already present in LULC Classes Column\n","    \"Roughness\",\n","    # \"Slope\",\n","    \"NDVI\", \"LST\", \"UHI\", \"UTFVI\", \"NDWI\", \"SAVI\", \"lulc_classes\", \"LandUse\", \"GHI\",\n","    # \"CH4\", \"CO\", \"HCHO\", \"NO2\", \"O3\", \"SO2\", # AIR QUIALITY\n","    \"Longitude\", \"Latitude\"\n","]\n","\n","# X_scaled, data = load_and_preprocess_data(DATASET_CSV, features)\n","\n","# # Load the trained model\n","# kmeans = load_model(MODEL_FILE)\n","\n","# # Predict the clusters for the new data\n","# clusters = kmeans.predict(X_scaled)\n","\n","# Perform inference\n","X_scaled, data, clusters, metrics = perform_inference(MODEL_FILE, DATASET_CSV, features)\n","\n","# Save the metrics to a CSV file\n","metrics_df = pd.DataFrame(list(metrics.items()), columns=['Metric', 'Value'])\n","metrics_df.to_csv(METRICS, index=False)\n","print(f\"Metrics Saved to: {METRICS}\")\n","\n","# Add the cluster assignments to the original data\n","data['Cluster'] = clusters\n","\n","# Save the data with cluster assignments to a new CSV file\n","\n","data.to_csv(DATA_WITH_CLUSTERS, index=False)\n","print(f\"Data with cluster assignments saved to: {DATA_WITH_CLUSTERS}\")"],"metadata":{"id":"OkvKAu_Ii_r-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_cols = data.columns.to_list()"],"metadata":{"id":"QCWjxnsiCsyn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Check if the lengths match\n","lengths_match = len(data_cols) == len(features)\n","print(f\"Lengths match: {lengths_match}\")\n","\n","# Check if all items match (regardless of order)\n","items_match = set(data_cols) == set(features)\n","print(f\"Items match: {items_match}\")\n","\n","# Check for any differences\n","missing_in_original = set(features) - set(data_cols)\n","missing_in_features = set(data_cols) - set(features)\n","\n","if not lengths_match or not items_match:\n","    print(\"Differences found:\")\n","    if missing_in_original:\n","        print(f\"Items in 'features' but not in 'original_list': {missing_in_original}\")\n","    if missing_in_features:\n","        print(f\"Items in 'original_list' but not in 'features': {missing_in_features}\")\n","else:\n","    print(\"Both lists match perfectly.\")"],"metadata":{"id":"PzvS2PEsDP5N"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data.info()"],"metadata":{"id":"b73ZFDcLBKZk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_scaled"],"metadata":{"id":"RhabzNQHBRVX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Visualize clusters\n","visualize_clusters(X_scaled, clusters, \"Clusters of Urban Agriculture Areas on New Data\")"],"metadata":{"id":"B62UPSSrp90C"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Visualize areas on map\n","visualize_areas_on_map(data, \"Clustered Areas for New Data\")"],"metadata":{"id":"ca-PirD4p-vA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Display relevant data\n","print(\n","    data[\n","        [\n","    \"soil_moisture\",\n","    \"NDBI\",\n","    # \"BU\", # Dropped since BU is already present in LULC Classes Column\n","    \"Roughness\",\n","    # \"Slope\",\n","    \"NDVI\", \"LST\", \"UHI\", \"UTFVI\", \"NDWI\", \"SAVI\", \"lulc_classes\", \"LandUse\", \"GHI\",\n","    # \"CH4\", \"CO\", \"HCHO\", \"NO2\", \"O3\", \"SO2\", # AIR QUIALITY\n","    \"Longitude\", \"Latitude\"\n","    ]\n","        ]\n","    )"],"metadata":{"id":"t0BPFelihT4z"},"execution_count":null,"outputs":[]}]}